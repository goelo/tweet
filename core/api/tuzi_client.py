#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tuzi API å®¢æˆ·ç«¯
å¤„ç†ä¸ Tuzi API çš„äº¤äº’
"""

import os
import sys
import json
import requests
from typing import List, Dict, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from core.config.config import config


class TuziClient:
    """Tuzi API å®¢æˆ·ç«¯"""

    def __init__(self):
        if not config:
            raise ValueError("é…ç½®æœªæ­£ç¡®åŠ è½½ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
        
        tuzi_config = config.get_tuzi_config()
        self.api_key = tuzi_config['api_key']
        self.api_base = tuzi_config['api_base']
        self.model = tuzi_config['model']
        
        if not self.api_key:
            raise ValueError("Tuzi API Key æœªè®¾ç½®")
        
        # ç¡®ä¿ API åŸºç¡€ URL æ­£ç¡®
        if not self.api_base.endswith('/chat/completions'):
            if self.api_base.endswith('/v1'):
                self.api_base = self.api_base + '/chat/completions'
            else:
                self.api_base = self.api_base.rstrip('/') + '/v1/chat/completions'
        
        self.headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        print(f"ğŸ¤– Tuzi API é…ç½®:")
        print(f"   API Base: {self.api_base}")
        print(f"   Model: {self.model}")
        print(f"   API Key: {self.api_key[:10]}...{self.api_key[-4:]}")

    def chat_completion(self, messages: List[Dict], temperature: float = 0.7, max_tokens: int = 2000) -> Optional[str]:
        """
        è°ƒç”¨ Tuzi Chat Completion API
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ token æ•°
            
        Returns:
            GPT çš„å›ç­”å†…å®¹
        """
        try:
            payload = {
                "model": self.model,
                "messages": messages,
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            response = requests.post(
                self.api_base,
                headers=self.headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                print(f"âŒ Tuzi API è°ƒç”¨å¤±è´¥: {response.status_code}")
                print(f"   å“åº”å†…å®¹: {response.text}")
                return None
                
        except Exception as e:
            print(f"âŒ Tuzi API è°ƒç”¨å¼‚å¸¸: {e}")
            return None

    def simple_chat(self, question: str, system_prompt: Optional[str] = None) -> Optional[str]:
        """
        ç®€å•çš„å¯¹è¯æ¥å£
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            GPT çš„å›ç­”
        """
        messages = []
        
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        messages.append({"role": "user", "content": question})
        
        return self.chat_completion(messages)

    def generate_thread(self, topic: str, thread_prompt: str) -> Optional[List[Dict]]:
        """
        ç”Ÿæˆ Twitter Thread
        
        Args:
            topic: è¯é¢˜æ ‡é¢˜
            thread_prompt: Thread ç”Ÿæˆæç¤ºè¯æ¨¡æ¿
            
        Returns:
            ç”Ÿæˆçš„ Thread åˆ—è¡¨
        """
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        full_prompt = thread_prompt.replace('${topic}', topic)
        
        response = self.simple_chat(
            full_prompt,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ“…é•¿å†™æé’± thread çš„ç¤¾äº¤åª’ä½“å†…å®¹åˆ›ä½œè€…ã€‚"
        )
        
        if not response:
            return None
        
        try:
            # å°è¯•è§£æ JSON æ ¼å¼çš„å›å¤
            thread_data = json.loads(response)
            if isinstance(thread_data, list):
                return thread_data
            else:
                print("âš ï¸ è¿”å›æ ¼å¼ä¸æ˜¯é¢„æœŸçš„åˆ—è¡¨æ ¼å¼")
                return None
        except json.JSONDecodeError:
            print("âš ï¸ æ— æ³•è§£æè¿”å›çš„ JSON æ ¼å¼")
            print(f"åŸå§‹å›å¤: {response}")
            return None

    def generate_image_prompt(self, topic: str, main_title: str, subtitle: str) -> str:
        """
        ç”Ÿæˆå›¾ç‰‡æç¤ºè¯
        
        Args:
            topic: è¯é¢˜å†…å®¹
            main_title: ä¸»æ ‡é¢˜
            subtitle: å‰¯æ ‡é¢˜
            
        Returns:
            å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
        """
        # ä½¿ç”¨ä½ æä¾›çš„å›¾ç‰‡æç¤ºè¯æ¨¡æ¿
        image_prompt = f"""Black background, large bold yellow Chinese text: '{main_title}'.
Below that in smaller white font: '{subtitle}'.
Center-aligned, minimalist layout, high contrast, 16:9 aspect ratio, suitable for attention-grabbing social media thumbnail."""
        
        return image_prompt

    def test_connection(self) -> bool:
        """
        æµ‹è¯• API è¿æ¥
        
        Returns:
            è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        test_response = self.simple_chat("Hello", "You are a helpful assistant.")
        return test_response is not None


# åˆ›å»ºå…¨å±€ Tuzi å®¢æˆ·ç«¯å®ä¾‹
try:
    tuzi_client = TuziClient()
except Exception as e:
    print(f"âŒ Tuzi å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    tuzi_client = None