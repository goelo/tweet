#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ç« æ ¼å¼è‰ç¨¿ç®¡ç†å™¨
ç”¨äºä¿å­˜å’Œç®¡ç†å®Œæ•´æ–‡ç« æ ¼å¼çš„è‰ç¨¿ï¼ˆéTwitter Threadæ ¼å¼ï¼‰
é€‚ç”¨äºå¾®åšã€å…¬ä¼—å·ç­‰å¹³å°
"""

import os
import json
import re
from datetime import datetime
from typing import List, Dict, Optional


class ArticleDraftManager:
    """æ–‡ç« æ ¼å¼è‰ç¨¿ç®¡ç†å™¨"""
    
    def __init__(self, drafts_dir: str = "output/articles"):
        """
        åˆå§‹åŒ–è‰ç¨¿ç®¡ç†å™¨
        
        Args:
            drafts_dir: è‰ç¨¿å­˜å‚¨ç›®å½•
        """
        self.drafts_dir = drafts_dir
        os.makedirs(self.drafts_dir, exist_ok=True)
    
    def thread_to_article(self, thread: List[Dict[str, str]], title: str = "", topic_info: Dict = None) -> str:
        """
        å°†Threadè½¬æ¢ä¸ºå¯Œæ–‡æœ¬æ ¼å¼æ–‡ç« 
        
        Args:
            thread: Threadåˆ—è¡¨
            title: æ–‡ç« æ ‡é¢˜
            topic_info: è¯é¢˜ä¿¡æ¯ï¼ˆåŒ…å«çº§åˆ«ã€å…³é”®è¯ç­‰ï¼‰
            
        Returns:
            å¯Œæ–‡æœ¬æ ¼å¼çš„æ–‡ç« å†…å®¹
        """
        if not thread:
            return ""
        
        # æå–æ‰€æœ‰æ¨æ–‡å†…å®¹
        tweets = []
        for item in thread:
            tweet_content = item.get('tweet', '').strip()
            if tweet_content:
                tweets.append(tweet_content)
        
        if not tweets:
            return ""
        
        # å¼€å§‹æ„å»ºå¯Œæ–‡æœ¬æ–‡ç« 
        article_parts = []
        
        # æ·»åŠ æ ‡é¢˜
        if title:
            article_parts.append(f"ã€{title}ã€‘")
            article_parts.append("")
        
        # å¤„ç†æ¨æ–‡å†…å®¹ï¼Œæ™ºèƒ½åˆå¹¶æˆæ®µè½
        processed_content = self._smart_merge_tweets(tweets, topic_info)
        article_parts.append(processed_content)
        
        # æ·»åŠ æ€»ç»“ï¼ˆä¸æ˜¾ç¤º"æ€»ç»“"æ ‡ç­¾ï¼‰
        if topic_info and topic_info.get('conclusion'):
            article_parts.append("")
            article_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
            article_parts.append("")
            article_parts.append(f"{topic_info['conclusion']}")
        
        return "\n".join(article_parts)
    
    def _smart_merge_tweets(self, tweets: List[str], topic_info: Dict = None) -> str:
        """
        æ™ºèƒ½åˆå¹¶æ¨æ–‡ä¸ºè¿è´¯çš„æ–‡ç« å†…å®¹ï¼Œå¹¶è‡ªç„¶èå…¥çº§åˆ«å’Œå…³é”®è¯ä¿¡æ¯
        
        Args:
            tweets: æ¨æ–‡åˆ—è¡¨
            topic_info: è¯é¢˜ä¿¡æ¯ï¼ˆåŒ…å«çº§åˆ«ã€å…³é”®è¯ç­‰ï¼‰
            
        Returns:
            åˆå¹¶åçš„æ–‡ç« å†…å®¹
        """
        if not tweets:
            return ""
        
        # æ¸…ç†å’Œå¤„ç†æ¯æ¡æ¨æ–‡
        processed_tweets = []
        
        for i, tweet in enumerate(tweets):
            # ç§»é™¤è¯é¢˜æ ‡ç­¾ (#xxx)
            clean_tweet = re.sub(r'#\w+', '', tweet)
            
            # ç§»é™¤è¿‡å¤šçš„è¡¨æƒ…ç¬¦å·ï¼ˆä¿ç•™å°‘é‡ï¼‰
            clean_tweet = re.sub(r'[ğŸš—ğŸ’¨ğŸ§ğŸ˜°âš ï¸ğŸ¤”ğŸ‘‡â¬‡ï¸]{2,}', ' ', clean_tweet)
            
            # ç§»é™¤æ•°å­—ç¼–å·ï¼ˆ1. 2. 3.ç­‰ï¼‰
            clean_tweet = re.sub(r'^\d+[.ã€]\s*', '', clean_tweet)
            
            # ç§»é™¤"è½¬å‘+è¯„è®º"ç­‰ç¤¾äº¤åª’ä½“ç‰¹æœ‰å†…å®¹
            clean_tweet = re.sub(r'è½¬å‘\+è¯„è®º.*$', '', clean_tweet)
            clean_tweet = re.sub(r'è½¬å‘.*è¯„è®º.*$', '', clean_tweet)
            
            # æ¸…ç†å¤šä½™ç©ºæ ¼
            clean_tweet = ' '.join(clean_tweet.split())
            
            if clean_tweet.strip():
                processed_tweets.append(clean_tweet.strip())
        
        if not processed_tweets:
            return ""
        
        # æ™ºèƒ½åˆå¹¶ä¸ºæ®µè½
        paragraphs = []
        current_paragraph = []
        
        for i, tweet in enumerate(processed_tweets):
            # ç¬¬ä¸€æ¡æ¨æ–‡é€šå¸¸æ˜¯å¼•è¨€/å¼€å¤´
            if i == 0:
                paragraphs.append(tweet)
                continue
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¼€å§‹æ–°æ®µè½
            should_start_new_paragraph = (
                # åŒ…å«é—®é¢˜å…³é”®è¯
                any(keyword in tweet for keyword in ['é—®é¢˜æ¥äº†', 'æ ¸å¿ƒé—®é¢˜', 'å…³é”®é—®é¢˜', 'é‚£ä¹ˆ', 'æ‰€ä»¥']) or
                # åŒ…å«æ€»ç»“å…³é”®è¯  
                any(keyword in tweet for keyword in ['æ€»ç»“', 'ç»“è®º', 'æœ€å', 'ç»¼ä¸Š']) or
                # åŒ…å«å¯¹æ¯”å…³é”®è¯
                any(keyword in tweet for keyword in ['ç„¶è€Œ', 'ä½†æ˜¯', 'ç›¸æ¯”ä¹‹ä¸‹', 'å¦ä¸€æ–¹é¢']) or
                # å½“å‰æ®µè½å·²ç»æ¯”è¾ƒé•¿äº†
                len('\n'.join(current_paragraph)) > 200
            )
            
            if should_start_new_paragraph and current_paragraph:
                # å®Œæˆå½“å‰æ®µè½
                paragraphs.append('\n'.join(current_paragraph))
                current_paragraph = [tweet]
            else:
                current_paragraph.append(tweet)
        
        # æ·»åŠ æœ€åä¸€ä¸ªæ®µè½
        if current_paragraph:
            paragraphs.append('\n'.join(current_paragraph))
        
        # åå¤„ç†ï¼šæ¸…ç†æ®µè½å†…å®¹
        final_paragraphs = []
        for paragraph in paragraphs:
            # ç§»é™¤æ®µè½å¼€å¤´çš„è½¬æŠ˜è¯
            paragraph = re.sub(r'^(é—®é¢˜æ¥äº†|æ ¸å¿ƒé—®é¢˜æ¥äº†|å…³é”®é—®é¢˜|é‚£ä¹ˆé—®é¢˜æ¥äº†)[ï¼š:]?\s*', '', paragraph)
            
            # å¤„ç†A/Bé€‰æ‹©é¢˜æ ¼å¼
            if re.search(r'[AB][.ã€]\s*', paragraph):
                paragraph = re.sub(r'åˆ°åº•æ˜¯[ï¼š:]?\s*A[.ã€]\s*', 'å¯èƒ½æ˜¯', paragraph)
                paragraph = re.sub(r'\s*B[.ã€]\s*', 'ï¼Œä¹Ÿå¯èƒ½æ˜¯', paragraph)
                paragraph = re.sub(r'\s*ï¼Ÿ$', 'ã€‚', paragraph)
            
            # æ¸…ç†å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹
            paragraph = re.sub(r'\s+', ' ', paragraph)
            paragraph = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*([^A-Za-z])', r'\1\2', paragraph)
            
            if paragraph.strip():
                final_paragraphs.append(paragraph.strip())
        
        # è‡ªç„¶èå…¥çº§åˆ«å’Œå…³é”®è¯ä¿¡æ¯
        result_text = '\n\n'.join(final_paragraphs)
        
        # åœ¨æ–‡ç« æœ«å°¾è‡ªç„¶æ·»åŠ çº§åˆ«å’Œå…³é”®è¯ä¿¡æ¯
        if topic_info:
            additional_info = []
            
            # æ ¹æ®çº§åˆ«æ·»åŠ å¯ä¿¡åº¦è¯´æ˜
            if topic_info.get('level') == 1:
                additional_info.append("ğŸ“‹ è¯¥æ¶ˆæ¯å·²å¾—åˆ°å®˜æ–¹ç¡®è®¤æˆ–å¤šå®¶ä¸»æµåª’ä½“æŠ¥é“ã€‚")
            elif topic_info.get('level') == 2:
                additional_info.append("ğŸ“‹ è¯¥æ¶ˆæ¯æ¥æºå¯é ï¼Œä½†ä»å¾…å®˜æ–¹æœ€ç»ˆç¡®è®¤ã€‚")
            elif topic_info.get('level') == 3:
                additional_info.append("ğŸ“‹ è¯¥æ¶ˆæ¯ä»ä¸ºä¼ é—»ï¼Œè¯·å…³æ³¨åç»­å®˜æ–¹æ¶ˆæ¯ã€‚")
            
            # æ·»åŠ å…³é”®è¯æ ‡ç­¾
            if topic_info.get('keywords'):
                keywords_list = [kw.strip() for kw in topic_info['keywords'].split('ã€')]
                hashtags = ' '.join([f"#{kw}" for kw in keywords_list])
                additional_info.append(f"ğŸ·ï¸ {hashtags}")
            
            if additional_info:
                result_text += '\n\n' + '\n'.join(additional_info)
        
        return result_text
    
    def save_article_draft(self, thread: List[Dict[str, str]], title: str = "", topic_info: Dict = None, images: List[str] = None) -> Optional[str]:
        """
        ä¿å­˜æ–‡ç« æ ¼å¼è‰ç¨¿ï¼ˆæ”¯æŒæ–‡ä»¶å¤¹ç»“æ„ï¼ŒåŒ…å«å›¾ç‰‡ï¼‰
        
        Args:
            thread: Threadåˆ—è¡¨
            title: æ–‡ç« æ ‡é¢˜
            topic_info: è¯é¢˜ä¿¡æ¯
            images: å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # è½¬æ¢ä¸ºæ–‡ç« æ ¼å¼
            article_content = self.thread_to_article(thread, title, topic_info)
            
            if not article_content:
                print("âŒ æ— æ³•ç”Ÿæˆæ–‡ç« å†…å®¹")
                return None
            
            # åˆ›å»ºæ—¥æœŸæ–‡ä»¶å¤¹
            now = datetime.now()
            date_folder = now.strftime("%Y-%m-%d")
            date_path = os.path.join(self.drafts_dir, date_folder)
            os.makedirs(date_path, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ç« æ–‡ä»¶å¤¹å
            timestamp = now.strftime("%H%M%S")
            safe_title = re.sub(r'[^\w\s\u4e00-\u9fff-]', '', title)[:30] if title else "untitled"
            safe_title = re.sub(r'\s+', '_', safe_title)
            folder_name = f"article_{safe_title}_{timestamp}"
            article_folder = os.path.join(date_path, folder_name)
            os.makedirs(article_folder, exist_ok=True)
            
            # ä¿å­˜æ–‡ç« å†…å®¹
            content_file = os.path.join(article_folder, "content.txt")
            with open(content_file, 'w', encoding='utf-8') as f:
                f.write(article_content)
            
            # ä¿å­˜å›¾ç‰‡æ–‡ä»¶
            if images:
                images_folder = os.path.join(article_folder, "images")
                os.makedirs(images_folder, exist_ok=True)
                
                for i, image_path in enumerate(images):
                    if os.path.exists(image_path):
                        try:
                            # è·å–æ–‡ä»¶æ‰©å±•å
                            _, ext = os.path.splitext(image_path)
                            new_image_name = f"image_{i+1}{ext}"
                            new_image_path = os.path.join(images_folder, new_image_name)
                            
                            # å¤åˆ¶å›¾ç‰‡æ–‡ä»¶
                            import shutil
                            shutil.copy2(image_path, new_image_path)
                            print(f"ğŸ“· å›¾ç‰‡å·²ä¿å­˜: {new_image_path}")
                        except Exception as e:
                            print(f"âš ï¸ å¤åˆ¶å›¾ç‰‡å¤±è´¥: {image_path} - {e}")
            
            # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
            metadata = {
                "title": title,
                "created_at": now.isoformat(),
                "topic_info": topic_info,
                "has_images": bool(images),
                "image_count": len(images) if images else 0,
                "content_file": "content.txt",
                "images_folder": "images" if images else None
            }
            
            metadata_file = os.path.join(article_folder, "metadata.json")
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“ æ–‡ç« è‰ç¨¿å·²ä¿å­˜åˆ°æ–‡ä»¶å¤¹: {article_folder}")
            if images:
                print(f"ğŸ“· åŒ…å« {len(images)} å¼ å›¾ç‰‡")
            return article_folder
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ç« è‰ç¨¿å¤±è´¥: {str(e)}")
            return None
    
    def list_article_drafts(self) -> List[str]:
        """
        åˆ—å‡ºæ‰€æœ‰æ–‡ç« è‰ç¨¿
        
        Returns:
            è‰ç¨¿æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´å€’åº
        """
        try:
            if not os.path.exists(self.drafts_dir):
                return []
            
            # è·å–æ‰€æœ‰.txtæ–‡ä»¶ï¼ˆåŒ…æ‹¬æ—¥æœŸæ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶ï¼‰
            draft_files = []
            
            # éå†ä¸»ç›®å½•ä¸­çš„ç›´æ¥æ–‡ä»¶ï¼ˆå‘åå…¼å®¹ï¼‰
            for filename in os.listdir(self.drafts_dir):
                file_path = os.path.join(self.drafts_dir, filename)
                if os.path.isfile(file_path) and filename.endswith('.txt') and filename.startswith('article_'):
                    draft_files.append(file_path)
            
            # éå†æ—¥æœŸæ–‡ä»¶å¤¹
            for item in os.listdir(self.drafts_dir):
                item_path = os.path.join(self.drafts_dir, item)
                if os.path.isdir(item_path) and re.match(r'\d{4}-\d{2}-\d{2}', item):
                    # è¿™æ˜¯ä¸€ä¸ªæ—¥æœŸæ–‡ä»¶å¤¹
                    try:
                        for filename in os.listdir(item_path):
                            file_path = os.path.join(item_path, filename)
                            if os.path.isfile(file_path) and filename.endswith('.txt') and filename.startswith('article_'):
                                draft_files.append(file_path)
                    except OSError:
                        continue
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            draft_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
            return draft_files
            
        except Exception as e:
            print(f"âŒ åˆ—å‡ºè‰ç¨¿å¤±è´¥: {str(e)}")
            return []
    
    def preview_article_draft(self, file_path: str):
        """
        é¢„è§ˆæ–‡ç« è‰ç¨¿
        
        Args:
            file_path: è‰ç¨¿æ–‡ä»¶è·¯å¾„
        """
        try:
            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f"\nğŸ“– æ–‡ç« è‰ç¨¿é¢„è§ˆ: {os.path.basename(file_path)}")
            print("=" * 60)
            print(content)
            print("=" * 60)
            print(f"ğŸ“Š æ–‡ç« ç»Ÿè®¡: {len(content)} å­—ç¬¦ï¼Œ{len(content.split())} è¯")
            
        except Exception as e:
            print(f"âŒ é¢„è§ˆè‰ç¨¿å¤±è´¥: {str(e)}")
    
    def delete_article_draft(self, file_path: str) -> bool:
        """
        åˆ é™¤æ–‡ç« è‰ç¨¿
        
        Args:
            file_path: è‰ç¨¿æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
            
            os.remove(file_path)
            print(f"âœ… å·²åˆ é™¤æ–‡ç« è‰ç¨¿: {os.path.basename(file_path)}")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ é™¤è‰ç¨¿å¤±è´¥: {str(e)}")
            return False


# å…¨å±€å®ä¾‹
article_draft_manager = ArticleDraftManager()